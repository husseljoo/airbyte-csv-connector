{
  "documentationUrl": "https://docs.airbyte.com/integrations/destinations/orange-hdfs",
  "supported_destination_sync_modes": ["overwrite", "append", "append_dedup"],
  "supportsIncremental": true,
  "connectionSpecification": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Destination Orange Hdfs",
    "type": "object",
    "required": ["hdfs_path", "sftp_max_requests"],
    "additionalProperties": false,
    "properties": {
      "hdfs_path": {
        "type": "string",
        "order": 0,
        "description": "The path in which the data will be saved in hdfs."
      },
      "hdfs_file": {
        "type": "string",
        "order": 1,
        "always_show": true,
        "description": "The filename which will be written to the hdfs path. (evaluates to filename if left empty)"
      },
      "variables": {
        "type": "array",
        "order": 2,
        "always_show": true,
        "default": [
          {
            "variable_name": "dt_formatted",
            "variable_value": "{date.strftime('%Y-%m-%d')}"
          },
          {
            "variable_name": "h",
            "variable_value": "{date.strftime('%H')}"
          }
        ],
        "items": {
          "type": "object",
          "required": ["variable_name", "variable_value"],
          "properties": {
            "variable_name": {
              "type": "string",
              "description": "Name of the variable"
            },
            "variable_value": {
              "type": "string",
              "description": "Name of the variable"
            }
          }
        }
      },
      "compress": {
        "type": "boolean",
        "default": false,
        "order": 3,
        "always_show": true,
        "description": "compress files before copying to hdfs"
      },
      "file_date_method": {
        "type": "object",
        "order": 4,
        "title": "File Date Extraction Method",
        "display_type": "radio",
        "oneOf": [
          {
            "title": "From Sftp server modification_time",
            "description": "Uses the modification time (unix timestamp) of the file present in the sftp server.",
            "required": ["method"],
            "properties": {
              "method": {
                "type": "string",
                "const": "modication_time_date",
                "order": 0
              }
            }
          },
          {
            "title": "From filename using regex",
            "description": "Extract the file date from the filename using regex.",
            "required": [
              "method",
              "filename_date_regex",
              "filename_date_format"
            ],
            "properties": {
              "method": {
                "type": "string",
                "const": "filename_date",
                "order": 0
              },
              "filename_date_regex": {
                "type": "string",
                "title": "Regex of the filename date extraction",
                "order": 1,
                "default": "(\\d{8})_(\\d{4})"
              },
              "filename_date_format": {
                "type": "string",
                "title": "The date format of the filename date extraction. The format parameter uses the same directives as those used by pythons strftime()e.g. %d%m%Y_%H%M%S",
                "order": 2,
                "default": "%d%m%Y_%H%M"
              }
            }
          }
        ]
      },
      "producers_number": {
        "type": "integer",
        "default": 5,
        "order": 0,
        "description": "Number of producers that copy files locally at once, defaults to 5.",
        "minimum": 1,
        "maximum": 100,
        "group": "workers"
      },
      "compress_workers_number": {
        "type": "integer",
        "default": 5,
        "order": 1,
        "description": "number of compress workers number, defaults to 5.",
        "minimum": 1,
        "maximum": 100,
        "group": "workers"
      },
      "consumers_number": {
        "type": "integer",
        "default": 5,
        "order": 2,
        "description": "Number of consumers that copy files to HDFS at once, defaults to 5.",
        "minimum": 1,
        "maximum": 100,
        "group": "workers"
      },
      "sftp_max_requests": {
        "type": "integer",
        "default": 128,
        "minimum": 1,
        "maximum": 250,
        "description": "Maximum number of parallel chunk transfers at once, defaults to 128."
      }
    },
    "groups": [
      {
        "id": "workers",
        "title": "Workers"
      }
    ]
  }
}
